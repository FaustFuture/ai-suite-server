# Vercel Serverless Deployment Guide

This guide explains how to deploy your backend as serverless functions on Vercel.

## ğŸš€ Performance Considerations

### **Advantages of Serverless:**
- âœ… **Auto-scaling**: Handles traffic spikes automatically
- âœ… **Pay-per-use**: Only pay for actual usage
- âœ… **Global CDN**: Fast response times worldwide
- âœ… **Zero maintenance**: No server management needed

### **Performance Optimizations:**
- âœ… **Cold start optimization**: Functions are optimized for quick startup
- âœ… **Connection pooling**: Supabase connections are reused
- âœ… **Memory limits**: 10MB file upload limit (Vercel Pro: 50MB)
- âœ… **Timeout limits**: 60s for file processing, 30s for responses

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ api/                          # Vercel serverless functions
â”‚   â”œâ”€â”€ index.js                  # Main endpoint
â”‚   â”œâ”€â”€ health.js                 # Health check
â”‚   â”œâ”€â”€ ingest-document.js        # File upload & processing
â”‚   â”œâ”€â”€ generate-response.js      # AI response generation
â”‚   â”œâ”€â”€ processing-stats/
â”‚   â”‚   â””â”€â”€ [agentId].js         # Get processing stats
â”‚   â””â”€â”€ delete-file/
â”‚       â””â”€â”€ [agentId]/
â”‚           â””â”€â”€ [fileHash].js     # Delete file chunks
â”œâ”€â”€ services/
â”‚   â””â”€â”€ KnowledgeIngestionService.js  # Core business logic
â”œâ”€â”€ vercel.json                   # Vercel configuration
â”œâ”€â”€ package.json                  # Dependencies
â””â”€â”€ .env.local                    # Environment variables
```

## ğŸ”§ Deployment Steps

### 1. **Install Vercel CLI**
```bash
npm i -g vercel
```

### 2. **Login to Vercel**
```bash
vercel login
```

### 3. **Deploy from Backend Directory**
```bash
cd backend
vercel
```

### 4. **Set Environment Variables**
In Vercel dashboard or CLI:
```bash
vercel env add SUPABASE_URL
vercel env add SUPABASE_ANON_KEY
vercel env add GEMINI_API_KEY
```

### 5. **Redeploy with Environment Variables**
```bash
vercel --prod
```

## ğŸŒ Frontend Configuration

Update your frontend to use the Vercel deployment URL:

```env
# In ai-agents/.env.local
NEXT_PUBLIC_BACKEND_URL=https://your-project.vercel.app
```

## ğŸ“Š Performance Monitoring

### **Vercel Analytics:**
- Function execution time
- Cold start frequency
- Error rates
- Memory usage

### **Optimization Tips:**
1. **Keep functions warm**: Use cron jobs or monitoring
2. **Optimize imports**: Use dynamic imports for heavy libraries
3. **Cache responses**: Implement caching for repeated requests
4. **Monitor memory**: Watch for memory leaks in long-running functions

## ğŸ”„ Local Development

For local development, you can still use the Express server:

```bash
cd backend
npm run dev
```

Or test serverless functions locally:

```bash
vercel dev
```

## ğŸš¨ Limitations & Considerations

### **Vercel Free Tier:**
- 100GB bandwidth/month
- 1000 serverless function invocations/day
- 10s execution time limit
- 50MB memory limit

### **Vercel Pro Tier:**
- Unlimited bandwidth
- Unlimited function invocations
- 60s execution time limit
- 1024MB memory limit
- 50MB file upload limit

### **File Processing:**
- Large files may hit timeout limits
- Consider chunking for very large documents
- PDF processing is optimized for serverless

## ğŸ” Troubleshooting

### **Common Issues:**
1. **Cold starts**: First request may be slower
2. **Memory limits**: Large files may cause issues
3. **Timeout errors**: Long processing may hit limits
4. **Import errors**: Ensure ES modules are properly configured

### **Debug Commands:**
```bash
# Check function logs
vercel logs

# Test locally
vercel dev

# Check deployment status
vercel ls
```
